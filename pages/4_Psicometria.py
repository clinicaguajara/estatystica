# REQUIRED IMPORTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import streamlit         as st
import pandas            as pd
import matplotlib.pyplot as plt

from sklearn.decomposition import PCA
from factor_analyzer       import FactorAnalyzer, calculate_kmo, calculate_bartlett_sphericity
from utils.design          import load_css

# CUSTOM FUNCTIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cronbach_alpha(df):
    """Calcula o alfa de Cronbach para um subconjunto de colunas numÃ©ricas."""
    df_corr = df.dropna().astype(float)
    k = df_corr.shape[1]
    variancias_itens = df_corr.var(axis=0, ddof=1)
    variancia_total = df_corr.sum(axis=1).var(ddof=1)
    if variancia_total == 0:
        return 0
    alpha = (k / (k - 1)) * (1 - (variancias_itens.sum() / variancia_total))
    return round(alpha, 4)

def render_psychometric_properties(df: pd.DataFrame, escalas_dict: dict):
    """Renderiza as propriedades psicomÃ©tricas de uma escala ou fator selecionado."""
    # Cores padrÃ£o (tema escuro)
    dark_bg = "#0E1117"
    white = "#FFFFFF"
    purple = "#7159c1"
    st.subheader("Propriedades PsicomÃ©tricas")

    if not escalas_dict:
        st.info("Crie uma escala primeiro para acessar esta anÃ¡lise.")
        return

    escala_nome = st.selectbox("Selecione a escala:", list(escalas_dict.keys()), key="escala_psico_select")
    escala_data = escalas_dict[escala_nome]

    fatores = escala_data.get("fatores", {})
    opcoes_nivel = ["Escala Total"] + list(fatores.keys())
    alvo = st.radio("Escolha o nÃ­vel de anÃ¡lise:", opcoes_nivel, key="nivel_analise_radio")

    cols = escala_data["itens"] if alvo == "Escala Total" else fatores[alvo]["itens"]
    df_target = df[cols].dropna()

    if df_target.shape[0] < 10:
        st.warning("NÃºmero de observaÃ§Ãµes insuficiente para anÃ¡lise psicomÃ©trica robusta.")
        return

    # KMO e Bartlett
    st.subheader("AdequaÃ§Ã£o da Amostra")
    kmo_all, kmo_model = calculate_kmo(df_target)
    chi_sq, p_value = calculate_bartlett_sphericity(df_target)
    st.write(f"KMO: **{round(kmo_model, 4)}**")
    st.write(f"Bartlett: Ï‡Â² = `{chi_sq:.2f}`, valor-p = `{p_value:.4g}`")

    if kmo_model >= 0.6 and p_value < 0.05:
        st.success("Amostra adequada para extraÃ§Ã£o fatorial.")
    else:
        st.warning("Amostra pode nÃ£o ser adequada para extraÃ§Ã£o fatorial.")

    # Alfa de Cronbach
    st.subheader("ConsistÃªncia Interna")
    alpha = cronbach_alpha(df_target)
    st.write(f"Alfa de Cronbach: **`{alpha}`**")

    # Escolha de mÃ©todo
    st.subheader("ExtraÃ§Ã£o Fatorial")
    metodo = st.selectbox(
        "Tipo de anÃ¡lise:",
        ["Nenhuma", "AnÃ¡lise Fatorial ExploratÃ³ria (EFA)", "Componentes Principais (PCA)", "Fatorial ConfirmatÃ³ria (em breve)"],
        key="metodo_analise_select"
    )

    if metodo == "AnÃ¡lise Fatorial ExploratÃ³ria (EFA)":
        fa = FactorAnalyzer(rotation='varimax')
        fa.fit(df_target)
        # Scree Plot com estilo escuro
        eigenvalues, _ = fa.get_eigenvalues()
        st.caption("""
        A AnÃ¡lise Fatorial ExploratÃ³ria (EFA) Ã© uma tÃ©cnica estatÃ­stica multivariada que busca identificar estruturas latentes (fatores) a partir de padrÃµes de correlaÃ§Ã£o entre variÃ¡veis observadas. 
        Ela Ã© amplamente utilizada em psicometria para investigar se um conjunto de itens pode ser agrupado em dimensÃµes subjacentes coerentes, como traÃ§os de personalidade ou habilidades cognitivas. 
        A EFA assume que os fatores nÃ£o sÃ£o observÃ¡veis diretamente, mas influenciam as respostas dos participantes aos itens medidos.
        """)
        st.markdown("##### ğŸ” Escolha o nÃºmero de fatores a extrair")
        st.caption("Visualize os autovalores (eigenvalues) e selecione abaixo a quantidade de fatores a manter.")

        dark_bg = "#0E1117"
        white = "#FFFFFF"
        purple = "#7159c1"

        fig, ax = plt.subplots(facecolor=dark_bg)
        ax.set_facecolor(dark_bg)

        ax.plot(range(1, len(eigenvalues) + 1), eigenvalues, marker="o", linestyle="-", color=purple)
        ax.set_title("Scree Plot (Eigenvalues)", color=white)
        ax.set_xlabel("Fator", color=white)
        ax.set_ylabel("Autovalor", color=white)
        ax.axhline(1, color='red', linestyle='--', linewidth=1.5)
        ax.tick_params(colors=white)
        for spine in ax.spines.values():
            spine.set_edgecolor(white)

        plt.tight_layout()
        st.pyplot(fig)

        # Slider e matriz
        n_fatores = st.slider("NÃºmero de fatores", min_value=1, max_value=len(eigenvalues), value=1, step=1, key="slider_n_fatores")

        fa_n = FactorAnalyzer(n_factors=n_fatores, rotation='varimax')
        fa_n.fit(df_target)

        st.dataframe(
            pd.DataFrame(
                fa_n.loadings_,
                index=cols,
                columns=[f"Fator {i+1}" for i in range(n_fatores)]
            )
        )

    # === PCA ===
    elif metodo == "Componentes Principais (PCA)":
        pca = PCA()
        explained = pca.fit(df_target).explained_variance_ratio_

        st.caption(
            "A PCA reduz dimensionalidade transformando variÃ¡veis correlacionadas em "
            "componentes ortogonais, ordenados por variÃ¢ncia explicada."
        )
        st.markdown("##### ğŸ” Escolha o nÃºmero de componentes principais")
        st.caption("Visualize a variÃ¢ncia explicada e selecione quantos componentes manter.")

        fig_pca, ax_pca = plt.subplots(facecolor=dark_bg)
        ax_pca.set_facecolor(dark_bg)
        ax_pca.plot(range(1, len(explained) + 1), explained,
                    marker="o", linestyle="-", color=purple)
        ax_pca.set_title("Scree Plot (PCA)", color=white)
        ax_pca.set_xlabel("Componente", color=white)
        ax_pca.set_ylabel("VariÃ¢ncia Explicada", color=white)
        ax_pca.tick_params(colors=white)
        for spine in ax_pca.spines.values():
            spine.set_edgecolor(white)
        plt.tight_layout()
        st.pyplot(fig_pca)

        n_components = st.slider("NÃºmero de componentes", 1, len(explained), 1, key="slider_n_pcs")
        pca_reduzido = PCA(n_components=n_components)
        pca_reduzido.fit(df_target)
        comps = pd.DataFrame(pca_reduzido.components_.T, index=cols,
                             columns=[f"PC{i+1}" for i in range(n_components)])
        st.dataframe(comps)



    elif metodo == "Fatorial ConfirmatÃ³ria (em breve)":
        st.info("Este mÃ³dulo serÃ¡ integrado futuramente com modelagem SEM.")

# PAGE 4 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

load_css()

st.title("Psicometria")

st.caption("""
A seÃ§Ã£o **Psicometria** oferece ferramentas para criaÃ§Ã£o, escoragem e avaliaÃ§Ã£o estatÃ­stica de escalas psicolÃ³gicas. 
Ã‰ possÃ­vel construir novas escalas a partir de itens selecionados, definir fatores internos e calcular indicadores fundamentais, 
como o **alfa de Cronbach** (consistÃªncia interna), o **KMO** e o **teste de esfericidade de Bartlett** (adequaÃ§Ã£o da amostra). 
TambÃ©m estÃ£o disponÃ­veis mÃ©todos de anÃ¡lise fatorial como a **EFA** (ExploratÃ³ria), **PCA** (AnÃ¡lise de Componentes Principais) 
e, em breve, **CFA** (ConfirmatÃ³ria). Ideal para pesquisadores que desejam validar construtos latentes de forma empÃ­rica.
""")

# Verify dataframe
if "dataframes" not in st.session_state or not st.session_state.dataframes:
    st.warning("Nenhum dataframe carreagdo.")
    st.stop()

df_names = list(st.session_state.dataframes.keys())
selected_df_name = st.selectbox("Selecione o dataframe para anÃ¡lise:", df_names)
df = st.session_state.dataframes[selected_df_name]
st.write(f"**DimensÃµes:** {df.shape[0]} Ã— {df.shape[1]}")

num_cols = df.select_dtypes(include="number").columns.tolist()
if not num_cols:
    st.warning("Este dataframe nÃ£o possui colunas numÃ©ricas.")
    st.stop()

st.divider()

# BODY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if "escalas" not in st.session_state:
    st.session_state["escalas"] = {}

if selected_df_name not in st.session_state["escalas"]:
    st.session_state["escalas"][selected_df_name] = {}

escalas_dict = st.session_state["escalas"][selected_df_name]


with st.expander("Reescalar itens com base 0", expanded=False):
    
    st.markdown("<br>", unsafe_allow_html=True)
    st.caption("Nas escalas do tipo Likert, os valores atribuÃ­dos Ã s alternativas representam postos ordinais, e nÃ£o quantidades absolutas. Por isso, o uso do valor zero como uma das opÃ§Ãµes pode ser conceitualmente inadequado. Isso porque o zero carrega um significado intervalar â€” ou seja, indica ausÃªncia absoluta do fenÃ´meno â€” enquanto as escalas de postos devem refletir apenas a intensidade relativa entre categorias. Ao utilizar zero, perde-se uma posiÃ§Ã£o vÃ¡lida na escala, o que reduz o nÃºmero efetivo de nÃ­veis de resposta e pode comprometer a lÃ³gica ordinal esperada. Por esse motivo, Ã© comum reescalar de 1 em diante (por exemplo, 1 a 5) itens com base 0 para preservar a estrutura de postos e garantir que todas as categorias representem graus vÃ¡lidos de expressÃ£o do fenÃ´meno.")
    
    itens_ajuste = st.multiselect(
        "Itens com base 0 que precisam ser reescalados:",
        options=df.columns.tolist(),  # ou selected_cols, ou todos_itens, dependendo do escopo
        key="itens_ajuste_base_zero"
    )

    aplicar_ajuste = st.button("Reescalar", use_container_width=True, key="btn_aplicar_ajuste")

    if aplicar_ajuste:
        for item in itens_ajuste:
            df[item] = df[item] + 1
        st.success(f"Ajuste aplicado: {len(itens_ajuste)} item(ns) foram incrementados em +1.")
        st.session_state.dataframes[selected_df_name] = df

with st.expander("InversÃ£o de itens", expanded=False):
    
    st.markdown("<br>", unsafe_allow_html=True)
    st.caption(
        "Selecione os itens cujos valores devem ser revertidos; "
        "o sistema detecta automaticamente o valor mÃ¡ximo observado, exibe e permite reverter em lote."
    )
    
    itens_reversos = st.multiselect(
        "Itens a serem revertidos:",
        options=df.columns.tolist(),
        key="itens_para_reversao"
    )

    if itens_reversos:
        # 1) detecta mÃ¡ximo observado em cada coluna
        maximos_detectados = {item: int(df[item].max()) for item in itens_reversos}

        # 2) exibe para o usuÃ¡rio
        st.markdown("#### MÃ¡ximos detectados para cada item:")
        for item, max_val in maximos_detectados.items():
            st.write(f"- `{item}`: {max_val}")

        placeholder_invert =st.empty()

        # 3) botÃ£o Ãºnico para reverter tudo
        if st.button(
            "Reverter itens selecionados",
            use_container_width=True,
            key="btn_aplicar_reversao"
        ):
            for item, max_val in maximos_detectados.items():
                df[item] = (max_val + 1) - df[item]
            placeholder_invert.success(f"ReversÃ£o aplicada para {len(itens_reversos)} item(ns).")
            st.session_state.dataframes[selected_df_name] = df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("Criar escala a partir de um conjunto de itens")
st.caption("O somatÃ³rio das novas escalas serÃ¡ mostrado e, opcionalmente, adicionado ao dataframe atual.")

# 1) Escolha de itens e tipo de soma
selected_cols = st.multiselect(
    "Itens para compor a escala",
    num_cols,
    key="escala_itens"
)
sum_type = st.radio(
    "Tipo de somatÃ³rio:",
    ["Normal", "BinÃ¡rio"],
    horizontal=True,
    key="escala_sum_type"
)

# 2) Threshold (apenas para binÃ¡rio)
threshold = None
if sum_type == "BinÃ¡rio" and selected_cols:
    min_val = int(df[selected_cols].min().min())
    max_val = int(df[selected_cols].max().max())
    st.caption("Cada item com valor maior ou igual ao limiar (threshold) contribui com 1 ponto. Abaixo dele, ponto zero.")
    threshold = st.number_input(
        "Threshold:",
        min_value=min_val,
        max_value=max_val,
        value=(min_val + max_val) // 2,
        step=1,
        format="%d",
        key="escala_threshold"
    )

# 3) Nome da escala
scale_name = st.text_input(
    "Nome da nova escala:",
    key="escala_nome"
)

# 4) OpÃ§Ã£o de salvar no df
save_to_df = st.checkbox("Salvar a escala no dataframe atual?", value=False, key="escala_save")

placeholder_scales = st.empty()

# 5) CriaÃ§Ã£o
if st.button("Criar escala", use_container_width=True):
    # validaÃ§Ãµes
    if not selected_cols:
        st.error("Selecione pelo menos um item.")
    elif not scale_name:
        st.error("Defina um nome para a escala.")
    elif save_to_df and scale_name in df.columns:
        st.error("JÃ¡ existe uma coluna com esse nome.")
    else:
        # cÃ¡lculo da sÃ©rie
        if sum_type == "Normal":
            new_series = df[selected_cols].sum(axis=1)
        else:
            new_series = (df[selected_cols] >= threshold).sum(axis=1)

        # mostra na tela
        st.write("#### Primeiro valores da escala criada:")
        st.dataframe(new_series.to_frame(scale_name).head())

        # salva se pedido
        if save_to_df:
            df[scale_name] = new_series
            st.session_state.dataframes[selected_df_name] = df
            placeholder_scales.success(f"Escala '{scale_name}' adicionada ao dataframe.")
        else:
            placeholder_scales.info(f"Escala '{scale_name}' salva na sessÃ£o.")

        # guarda metadados sempre
        escalas_dict[scale_name] = {
            "itens": selected_cols,
            "tipo": sum_type,
            "threshold": threshold,
            "valores": new_series.tolist(),
            "fatores": {}
        }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SEÃ‡ÃƒO 3 â€” DEFINIR FATORES EM UMA ESCALA
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if escalas_dict:
    st.subheader("Definir fatores")
    escala_selecionada = st.selectbox(
        "Escolha a escala-alvo",
        list(escalas_dict.keys()),
        key="escala_fator"
    )
    escala_data = escalas_dict[escala_selecionada]
    todos_itens = escala_data["itens"]
    fatores_atuais = escala_data.get("fatores", {})

    with st.form("form_fator"):
        nome_fator = st.text_input("Nome do novo fator", key="input_fator_nome")
        itens_fator = st.multiselect(
            "Itens que compÃµem este fator",
            todos_itens,
            key="multiselect_fator_itens"
        )
        save_factor = st.checkbox(
            "Salvar este fator no dataframe atual?",
            value=False,
            key="save_fator_checkbox"
        )

        placehold_add_factor = st.empty()
        criar_fator = st.form_submit_button(
            "Adicionar fator",
            use_container_width=True
        )
    
    if criar_fator:
        if not nome_fator or not itens_fator:
            st.error("Preencha o nome do fator e selecione pelo menos um item.")
        else:
            # Calcula os valores do fator
            valores_fator = df[itens_fator].sum(axis=1).tolist()
            
            # Armazena no dicionÃ¡rio interno
            escala_data.setdefault("fatores", {})[nome_fator] = {
                "itens": itens_fator,
                "valores": valores_fator
            }

            # Se o usuÃ¡rio marcou para salvar, cria a coluna no DataFrame
            nome_coluna = f"{escala_selecionada}_{nome_fator}"
            if save_factor:
                df[nome_coluna] = valores_fator
                st.session_state.dataframes[selected_df_name] = df
                placehold_add_factor.success(
                    f"Fator '{nome_fator}' adicionado e salvo como coluna '{nome_coluna}'."
                )
            else:
                placehold_add_factor.info(
                    f"Fator '{nome_fator}' criado em memÃ³ria, mas NÃƒO salvo no DataFrame."
                )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SEÃ‡ÃƒO 4 â€” VISUALIZAR ESCALAS E FATORES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for nome, dados in escalas_dict.items():
    st.markdown(f"### ğŸ§® Escala: **{nome}**")
    st.markdown(f"Composta por: `{', '.join(dados['itens'])}`")
    st.line_chart(dados["valores"])

    fatores = dados.get("fatores", {})

    if fatores:
        st.markdown("#### ğŸ“š Fatores:")
        for fator_nome, fator_info in list(fatores.items()):
            with st.expander(f"{fator_nome}", expanded=False):
                
                st.markdown("<br>", unsafe_allow_html=True)
                st.markdown(f"**Itens:** `{', '.join(fator_info['itens'])}`")
                st.line_chart(fator_info["valores"])

                delete = st.button(
                    f"ğŸ—‘ï¸ Deletar fator",
                    key=f"delete_fator_{nome}_{fator_nome}",
                    use_container_width=True
                )

                if delete:
                    del fatores[fator_nome]
                    col_to_drop = f"{nome}_{fator_nome}"
                    if col_to_drop in df.columns:
                        df.drop(columns=[col_to_drop], inplace=True)
                    st.session_state.dataframes[selected_df_name] = df
                    st.rerun()


render_psychometric_properties(df, escalas_dict)